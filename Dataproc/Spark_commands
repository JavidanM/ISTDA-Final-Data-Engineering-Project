spark-shell --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2 --jars=gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar

import spark.implicits._

import org.apache.spark.sql.types._

import org.apache.spark.sql.functions

import java.sql.Timestamp

import org.apache.spark.sql.streaming.Trigger.ProcessingTime

val bucket = "istdaproject1"

spark.conf.set("temporaryGcsBucket",bucket)

spark.conf.set("parentProject","striking-effort-378509")

val kafkaDF = spark.readStream.format("kafka").option("kafka.bootstrap.servers","34.125.21.65:9092").option("subscribe","citytemp").load


val schema = StructType(List(StructField("city_name",StringType),StructField("country",StringType),StructField("localtime",DataTypes.DateType),StructField("temp_c",FloatType)))

val activationDF = kafkaDF.select(from_json($"value".cast("string"),schema).alias("activation"))

val df = activationDF.select($"activation"("city_name").alias("name"),$"activation"("country").alias("country"),$"activation"("localtime").alias("localtime"),$"activation"("temp_c").alias("temp_c"))

val modelCountDF = df.filter($"activation"("temp_c")>0)

val modelCountQuery = modelCountDF.writeStream.outputMode("append").format("bigquery").option("table","finalproject.weatherbycities_table").option("checkpointLocation","/path/to/checkpoint/dir/in/hdfs").option("credentialsFile","/home/javamammadov93/cert.json").option("failOnDataLoss",false).option("truncate",false).start().awaitTermination()
